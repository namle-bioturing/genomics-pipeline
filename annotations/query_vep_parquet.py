#!/usr/bin/env python3
"""
Query VEP Parquet File Examples

This script demonstrates various queries on the VEP-annotated variant Parquet file
using Polars for high-performance data analysis.

Usage:
    python query_vep_parquet.py results.parquet
"""

import sys
import time
from pathlib import Path
from typing import Optional

import polars as pl


def time_query(query_name: str, query_func):
    """
    Time a query execution and print results.

    Args:
        query_name: Name of the query
        query_func: Function that executes the query and returns result

    Returns:
        Query result
    """
    start_time = time.time()
    result = query_func()
    elapsed = time.time() - start_time

    print(f"\nâ±ï¸  Query time: {elapsed:.4f} seconds ({elapsed*1000:.2f} ms)")
    print(f"ðŸ“Š Returned {len(result):,} records")

    return result


# Note: All examples use pl.scan_parquet() directly for optimal lazy evaluation
# No need for separate helper functions - each example builds its own query pipeline


def example_1_chromosome_position(parquet_file: Path) -> None:
    """
    Example 1: Lazy load + filter chromosome 1, sorted by position, first 30 records.

    Pattern: scan â†’ filter â†’ sort â†’ limit â†’ collect
    """
    print("\n" + "=" * 80)
    print("EXAMPLE 1: Lazy load chr1, sorted by position, first 30 records")
    print("=" * 80)

    def query():
        return (
            pl.scan_parquet(parquet_file)    # Lazy scan
            .filter(pl.col("chrom") == "chr1")  # Filter pushed to file reader
            .sort("pos")                      # Sort
            .head(30)                         # Limit to 30
            .collect()                        # Execute optimized plan
        )

    result = time_query("Lazy: chr1 filter + sort", query)
    print(result)


def example_2_specific_gene(parquet_file: Path, gene_name: str = "BRCA1") -> None:
    """
    Example 2: Lazy load + filter specific gene (first 30 records).

    Pattern: scan â†’ filter gene â†’ sort â†’ limit â†’ collect
    """
    print("\n" + "=" * 80)
    print(f"EXAMPLE 2: Lazy load {gene_name} variants (first 30)")
    print("=" * 80)

    def query():
        return (
            pl.scan_parquet(parquet_file)
            .filter(pl.col("gene") == gene_name)  # Filter pushed to file reader
            .sort(["chrom", "pos"])
            .head(30)
            .collect()
        )

    result = time_query(f"Lazy: {gene_name} filter", query)
    print(result)


def example_3_high_impact_variants(parquet_file: Path) -> None:
    """
    Example 3: Lazy load + filter high-impact variants (stop gained, frameshift), first 30.

    Pattern: scan â†’ filter consequence â†’ sort â†’ limit â†’ collect
    """
    print("\n" + "=" * 80)
    print("EXAMPLE 3: Lazy load high-impact variants (stop_gained, frameshift), first 30")
    print("=" * 80)

    def query():
        return (
            pl.scan_parquet(parquet_file)
            .filter(
                pl.col("consequence").str.contains("stop_gained") |
                pl.col("consequence").str.contains("frameshift")
            )
            .sort(["chrom", "pos"])
            .head(30)
            .collect()
        )

    result = time_query("Lazy: high-impact filter", query)
    print(result)


def example_4_rare_variants(parquet_file: Path, max_af: float = 0.01) -> None:
    """
    Example 4: Lazy load + filter rare variants (gnomAD AF < 1%), first 30.

    Pattern: scan â†’ filter AF â†’ select columns â†’ sort â†’ limit â†’ collect
    """
    print("\n" + "=" * 80)
    print(f"EXAMPLE 4: Lazy load rare variants (gnomADg_af < {max_af}), first 30")
    print("=" * 80)

    def query():
        return (
            pl.scan_parquet(parquet_file)
            .filter(
                # (pl.col("gnomadg_af").cast(pl.Float64) < max_af) |
                # pl.col("gnomadg_af").is_null()
                pl.col("am_class").is_not_null()
            )
            .select(["chrom", "pos", "ref", "alt", "gene", "gnomadg_af", "revel", "am_class"])  # Column pruning
            .sort(["chrom", "pos"])
            .head(30)
            .collect()
        )

    result = time_query("Lazy: rare variants filter", query)
    print(result)


def example_5_pathogenic_variants(parquet_file: Path) -> None:
    """
    Example 5: Lazy load + filter pathogenic/likely pathogenic variants from ClinVar, first 30.

    Pattern: scan â†’ filter clinsig â†’ select columns â†’ sort â†’ limit â†’ collect
    """
    print("\n" + "=" * 80)
    print("EXAMPLE 5: Lazy load pathogenic/likely pathogenic variants (ClinVar), first 30")
    print("=" * 80)

    def query():
        return (
            pl.scan_parquet(parquet_file)
            .filter(
                pl.col("clinsig").str.contains("pathogenic") |
                pl.col("clinsig").str.contains("likely_pathogenic")
            )
            .select(["chrom", "pos", "ref", "alt", "gene", "clinsig"])  # Column pruning
            .sort(["chrom", "pos"])
            .head(30)
            .collect()
        )

    result = time_query("Lazy: pathogenic filter", query)
    print(result)


def example_6_specific_region(parquet_file: Path, chrom: str = "chr17",
                               start: int = 43000000, end: int = 43100000) -> None:
    """
    Example 6: Lazy load + filter variants in a specific genomic region, first 30.

    Pattern: scan â†’ filter region â†’ sort â†’ limit â†’ collect
    """
    print("\n" + "=" * 80)
    print(f"EXAMPLE 6: Lazy load variants in region {chrom}:{start:,}-{end:,}, first 30")
    print("=" * 80)

    def query():
        return (
            pl.scan_parquet(parquet_file)
            .filter(
                (pl.col("chrom") == chrom) &
                (pl.col("pos") >= start) &
                (pl.col("pos") <= end)
            )
            .sort("pos")
            .head(30)
            .collect()
        )

    result = time_query("Lazy: region filter", query)
    print(result)


def example_7_missense_with_prediction(df: pl.DataFrame) -> None:
    """
    Example 7: Get missense variants with damaging predictions, first 30.
    """
    print("\n" + "=" * 80)
    print("EXAMPLE 7: Missense variants with damaging predictions (SIFT/PolyPhen), first 30")
    print("=" * 80)

    def query():
        return (
            df
            .filter(
                pl.col("consequence").str.contains("missense_variant") &
                (
                    pl.col("sift").str.contains("deleterious") |
                    pl.col("polyPhen").str.contains("damaging")
                )
            )
            .sort(["chrom", "pos"])
            .select(["chrom", "pos", "ref", "alt", "gene", "sift", "polyPhen"])
            .head(30)
        )

    result = time_query("Damaging missense filter", query)
    print(result)


def example_8_variant_summary_stats(df: pl.DataFrame) -> None:
    """
    Example 8: Summary statistics - variants per chromosome.
    """
    print("\n" + "=" * 80)
    print("EXAMPLE 8: Summary statistics - variants per chromosome")
    print("=" * 80)

    stats = (
        df
        .group_by("chrom")
        .agg([
            pl.col("variant_id").n_unique().alias("unique_variants"),
            pl.col("pair_id").count().alias("total_pairs"),
            pl.col("gene").n_unique().alias("unique_genes")
        ])
        .sort("chrom")
    )

    print("\nVariants per chromosome:")
    print(stats)


def example_9_top_genes(df: pl.DataFrame, top_n: int = 20) -> None:
    """
    Example 9: Top genes with most variants.
    """
    print("\n" + "=" * 80)
    print(f"EXAMPLE 9: Top {top_n} genes with most variants")
    print("=" * 80)

    top_genes = (
        df
        .group_by("gene")
        .agg([
            pl.col("variant_id").n_unique().alias("unique_variants"),
            pl.col("pair_id").count().alias("total_pairs")
        ])
        .sort("unique_variants", descending=True)
        .head(top_n)
    )

    print(f"\nTop {top_n} genes:")
    print(top_genes)


def example_10_filter_multiple_conditions(df: pl.DataFrame) -> None:
    """
    Example 10: Complex query - rare, pathogenic, protein-altering variants.
    """
    print("\n" + "=" * 80)
    print("EXAMPLE 10: Complex query - rare + pathogenic + protein-altering")
    print("=" * 80)

    result = (
        df
        .with_columns(
            pl.col("gnomadg_af").cast(pl.Float64).alias("gnomadg_af_float")
        )
        .filter(
            # Rare (AF < 0.01 or null)
            (
                (pl.col("gnomadg_af_float") < 0.01) |
                pl.col("gnomadg_af_float").is_null()
            ) &
            # Pathogenic
            (
                pl.col("clinsig").str.contains("pathogenic").fill_null(False)
            ) &
            # Protein-altering
            (
                pl.col("consequence").str.contains("missense_variant") |
                pl.col("consequence").str.contains("stop_gained") |
                pl.col("consequence").str.contains("frameshift")
            )
        )
        .sort(["chrom", "pos"])
    )

    print(f"\nFound {len(result):,} variants matching all criteria")
    print(result.select(["chrom", "pos", "ref", "alt", "gene", "consequence", "clinsig", "gnomadg_af"]).head(10))


def example_11_export_subset(df: pl.DataFrame, output_file: str = "filtered_variants.parquet") -> None:
    """
    Example 11: Export filtered results to new Parquet file.
    """
    print("\n" + "=" * 80)
    print("EXAMPLE 11: Export filtered results")
    print("=" * 80)

    # Filter for chromosome 1, rare variants
    filtered = (
        df
        .filter(pl.col("chrom") == "1")
        .with_columns(
            pl.col("gnomadg_af").cast(pl.Float64).alias("gnomadg_af_float")
        )
        .filter(
            (pl.col("gnomadg_af_float") < 0.01) |
            pl.col("gnomadg_af_float").is_null()
        )
    )

    print(f"\nExporting {len(filtered):,} records to {output_file}")
    filtered.write_parquet(output_file, compression="zstd")
    print(f"[SUCCESS] Exported to {output_file}")


def example_12_null_handling(df: pl.DataFrame) -> None:
    """
    Example 12: Working with null values.
    """
    print("\n" + "=" * 80)
    print("EXAMPLE 12: Null value handling")
    print("=" * 80)

    # Count nulls in key columns
    null_counts = df.select([
        pl.col("qual").is_null().sum().alias("qual_nulls"),
        pl.col("dp").is_null().sum().alias("dp_nulls"),
        pl.col("rsid").is_null().sum().alias("rsid_nulls"),
        pl.col("clinsig").is_null().sum().alias("clinsig_nulls"),
        pl.col("gnomadg_af").is_null().sum().alias("gnomadg_af_nulls")
    ])

    print("\nNull value counts:")
    print(null_counts)

    # Get records with non-null rsID (known variants)
    known_variants = (
        df
        .filter(pl.col("rsid").is_not_null())
        .sort(["chrom", "pos"])
    )

    print(f"\nFound {len(known_variants):,} variants with rsID")
    print(known_variants.select(["chrom", "pos", "ref", "alt", "gene", "rsid"]).head(10))


def main():
    """
    Main function to run all query examples.

    All examples use the OPTIMAL pattern for large files:
    - Lazy scan (no upfront data loading)
    - Filter during file read (predicate pushdown)
    - Select only needed columns (projection pushdown)
    - Collect only matching records

    This is 5-10x faster than loading all data first!
    """
    if len(sys.argv) < 2:
        print("Usage: python query_vep_parquet.py <parquet_file>")
        print("\nExample:")
        print("  python query_vep_parquet.py results.parquet")
        print("\nOptimal Pattern (used by ALL examples):")
        print("  âœ“ Lazy scan - no upfront data loading")
        print("  âœ“ Filter during file read (predicate pushdown)")
        print("  âœ“ Select only needed columns (projection pushdown)")
        print("  âœ“ Collect only matching records")
        print("\nBenefits for 5M+ rows:")
        print("  â€¢ 5-10x faster than eager loading all data")
        print("  â€¢ 90% less memory usage")
        print("  â€¢ Automatic query plan optimization")
        sys.exit(1)

    parquet_file = Path(sys.argv[1])

    if not parquet_file.exists():
        print(f"[ERROR] File not found: {parquet_file}")
        sys.exit(1)

    # Check file size
    file_size_mb = parquet_file.stat().st_size / (1024 * 1024)
    print(f"\n{'='*80}")
    print(f"VEP Parquet Query Examples - Lazy Load + Filter Pattern")
    print(f"{'='*80}")
    print(f"[INFO] Parquet file: {parquet_file}")
    print(f"[INFO] File size: {file_size_mb:.1f} MB")
    print(f"\n[INFO] All examples use lazy evaluation for optimal performance")
    print(f"[INFO] No data loaded until each query executes")

    # Run examples - all use lazy load + filter pattern
    print("\n" + "=" * 80)
    print("ðŸš€ Running Examples - All use LAZY LOAD + FILTER for optimal performance")
    print("=" * 80)

    try:
        example_1_chromosome_position(parquet_file)
        example_2_specific_gene(parquet_file, "BRCA1")
        example_3_high_impact_variants(parquet_file)
        example_4_rare_variants(parquet_file, max_af=0.01)
        example_5_pathogenic_variants(parquet_file)
        example_6_specific_region(parquet_file, chrom="chr17", start=43000000, end=43100000)

        # Optional examples (commented out by default)
        # example_7_missense_with_prediction(parquet_file)
        # example_8_variant_summary_stats(parquet_file)
        # example_9_top_genes(parquet_file, top_n=20)
        # example_10_filter_multiple_conditions(parquet_file)
        # example_11_export_subset(parquet_file, "filtered_variants.parquet")
        # example_12_null_handling(parquet_file)

        print("\n" + "=" * 80)
        print("âœ“ All examples completed successfully!")
        print("=" * 80)

    except Exception as e:
        print(f"\n[ERROR] An error occurred: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
